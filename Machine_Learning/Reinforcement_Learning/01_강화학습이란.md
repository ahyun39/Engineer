# CH01. 강화학습이란?

## 1.1. 지도학습과 강화학습

### 기계 학습의 분류

<p align="center">
<img src="https://github.com/user-attachments/assets/2e0e0c29-3fe5-49b7-bd76-903b365bee01" width=130 height=100></p>


- 비지도 학습
    - 생성 모델 → 사람 얼굴 사진의 분포를 학습 (새로운 얼굴 생성)
    - 클러스터링 → 주어진 데이터 中 성질이 비슷한 것 묶어

<지도 vs. 강화>
- 지도학습 : 지도자 → 학습
- 강화학습 : 시행착오 → 학습

### 지도 학습
_지도자 or 정답이 주어짐_

- 학습 데이터 : 학습에 사용되는 데이터
- 테스터 데이터 : 정답을 맞히고자 하는 데이터
    
    ⇒ 학습 데이터를 이용해 인풋과 정답 사이 관계를 학습하여 테스트 상황에서 정답을 맞힐 수 있는 인공지능을 학습하는 방법

### 강화 학습

"순차적 의사결정 문제에서 누적 보상을 최대화하기 위해 시행착오를 통해 행동을 교정하는 학습과정"

<br>

## 1.2. 순차적 의사결정 문제
_강화학습이 풀고자 하는 문제_

- 예시 1) 샤워 - ①옷× ②샤워 ③수건 ④옷○ → 순서가 바뀐다면 문제 발생, 행동 -(영향)→ 상황
- 예시 2) 주식투자 포트폴리오 - 시장상황에 따라 유연하게 포트폴리오 재구성
- 예시 3) 운전 - 도로 이용, 차선, 조작 → 연쇄작용
- 예시 4) 게임 - 영웅 선택 → 라인

<br>

## 1.3. 보상
_의사결정을 얼마나 잘하고 있는지 알려주는 신호_

- 누적보상(과정에서 받는 보상의 총합)을 최대화하는 것이 강화학습의 목적

### 보상의 특징
1. `어떻게`에 대한 정보X → `얼마나` 잘 하고 있는지 평가
    
    ⇒ 따라서, 보상이 낮은 행동_넘어짐 ↓ + 보상이 높은 행동_안 넘어짐 ↑
    
    ⇒ 결과적으로, 보상을 최대화

2. 보상이 `스칼라`
    
    예시) 학생의 목표가 (𝑥(학점), 𝑦(동아리), 𝑧(연애))일 때, 하나의 스칼라로 표현? '가중치'를 두는 방법
    
    → [학점 중요시 하는 경우] (50%, 25%, 25%) → 0.5𝑥 + 0.25𝑦 + 0.25𝑧

    - 하나의 목표를 설정하기 어렵다면? 강화학습 적용이 적절하지 X

    <스칼라 보상 예시>
        
        - 자산 포트폴리오 배분에서의 이득, 자전거 타기에서 넘어지지 않고 나아간 거리, 게임에서의 승리

3. 보상이 희소할 수 있으며 지연될 수 있음

    예시) 바둑 250수 - 보상 1개 : 250개의 행동 中 어떤 행동이 문제가 있었는지 알기 어려움.

    =(해결)⇒ 밸류 네트워크

\* 순차적 의사결정 문제이기 때문에 순차성, 즉 시간에 따른 흐름이 중요

이 흐름에서 보상이 뒤늦게 주어지는 것이 가능

<br>

## 1.4. 에이전트와 환경

<p align="center">
<img src="https://github.com/user-attachments/assets/657aa654-aad2-4056-a3fa-9c5463e1e11c" width=300 height=120></p>

### 에이전트 : 학습하는 대상, 행동 객체

1. 현재 상황 $S_t$에서 어떤 액션을 해야할 지 $a_t$를 결정

2. 결정된 행동 $a_t$를 환경으로 보냄

3. 환경으로부터 그에 따른 보상과 다음 상태의 정보를 받음

### 상태 : 현재 상태에 대한 모든 정보를 숫자로 표현하여 기록한 것

ex) 자전거가 조금 앞으로 이동, 기울기나 핸들 각도 변화 ...

### 환경 : 상태 변화를 일으키는 역할을 담당
_환경: 행동의 결과를 알려주는 것_

1. 에이전트로부터 받은 액션 $a_t$를 통해서 상태변화를 일으킴

2. 그 결과 상태는 $S_t → S_{t+1}$로 바뀜

3. 에이전트에게 줄 보상 $r_{t+1}$도 함께 계산

4. $S_{t+1}$과 $r_{t+1}$을 에이전트에게 전달

<br>

## 1.5. 강화학습의 위력

### 병렬성의 힘

<p align="center">
<img src="https://github.com/user-attachments/assets/cec768c7-66b3-4768-8432-388397f69f83" width=200 height=100></p>

- 강화학습은 경험을 쌓는 부분의 병렬성을 쉽게 증가

### 자가학습의 매력

- 독학 → 강화학습 ⇒ (깨우칠 수 있는)지식의 한계 X
- 알파고
    - 승리라는 목표만 알려줬을 뿐 그 과정은 알아서 찾도록 했기 때문에 충분한 계산능력과 어우러져 사람이 생각해낼 수 없는 수를 찾아냄.