# 데이터 표준화 및 협업 프로세스 개선 프로젝트

## 1. 프로젝트 개요
전사 데이터의 일관성을 확보하고 데이터 기반 의사결정을 효율화하기 위해 **표준 단어·용어·코드 체계 구축**과 **협업 프로세스를 개선**하는 프로젝트를 수행했습니다.
다양한 인스턴스와 서비스에서 동일한 의미의 데이터가 서로 다른 방식으로 정의되어 **중복, 불일치, 의미 왜곡**이 발생하는 문제를 해결하고자 했습니다.

---

## 2. 주요 역할 및 기여

- **데이터 표준화**
  - 표준 단어/용어/코드 정의 및 표준화 프로세스 설계
- **자동화 도입**
  - Python + Kiwi 형태소 분석기를 활용한  
    컬럼 코멘트 분석 및 표준 단어 후보 자동 추출 로직 개발
- **메타데이터 분석**
  - Dataware, 쿼리파이를 활용한 DB 컬럼 현황 분석
- **협업 방식 개선**
  - 위키 기반 회의록, 슬랙 캔버스, 주차별 개인 일지 도입
- **가이드라인 정립**
  - Q&A 카테고리화 및 표준 단어 생성 규칙·가이드라인 수립

---

## 3. 세부 프로세스

### 3.1. 표준 단어/용어/코드 정의
- 언더스코어 기반 단어 분리를 활용해 **16만 건 이상의 메타데이터**를 정제하고  
  **6,179개의 표준화 대상 컬럼**을 선별
- 컬럼명, 코멘트, 데이터 타입/길이를 기준으로 표준 단어 생성 규칙 수립
- 사용 빈도 기반으로  
  - 포괄적 용어(예: *단위 유형 코드*, *전체 여부*)  
  - 단일 컬럼 특화 용어  
  를 구분하여 정의
- 코드값 검증을 통해 데이터의 의미가 코드가 아닌 경우  
  `_코드` → `_값`, `_내용` 등으로 재정의하여 의미 정확성 확보

---

### 3.2. 자동화 · 분석을 통한 효율 향상
#### ✔ Python + Kiwi 기반 자동화 로직 구현
- 컬럼 코멘트 형태소 분리 후 **단어 빈도 계산 → 후보 단어 추천 모델** 개발
- 특정 영문 단어(add, status 등)가 포함된 컬럼들의 모든 코멘트를 분석하여  
  **정량적 기준으로 한글 단어 정의**
- 컬럼명 필터링 → 코멘트 분석 → 표준화 여부 판별까지  
  **일괄 자동 처리 파이프라인 설계**

```python
# Kiwi 활용 예시)

# 1. kiwi로 형태소 분리하기
from kiwipiepy import Kiwi, Match
kiwi = Kiwi()

# 예를 들어, type에 대한 comment를 분석한다고 하자.
inputs = ['type'에 대한 모든 comment]

inputs = ['생성일시', '수정일시', '종료일자', '가입일자', '계약일자']

tokens = []

for word in inputs:
    tokenization = kiwi.tokenize(word, normalize_coda=True)
    for i in range(len(tokenization)):
        tokens.append(tokenization[i][0])
print(tokens)

# 출력 결과 예시: ['생성', '일시', '수정', '일시', '종료일', '자', '가입', '일자', '계약', '일자']

# 2. 단어별 분리된 형태소 비율 계산

import pandas as pd

# 예시 데이터프레임
# dict_df: 영문 단어와 한글 단어, 그에 대한 comment_cnt
dict_df = pd.DataFrame({
    'en_word': ['receipt', 'receipt', 'receipt', 'receipt'],
    'ko_word': ['영수증', '받기', '수령액', '영수증'],
    'comment_cnt': [2, 0, 0, 1]
})

# comment_df: 다른 데이터프레임 (예시로 동일한 데이터 사용)
comment_df = pd.DataFrame({
    'en_word': ['receipt', 'receipt', 'receipt', 'receipt'],
    'ko_word': ['영수증', '받기', '수령액', '영수증'],
    'comment_cnt': [3, 0, 0, 1]
})

# 1) 두 데이터프레임을 합침
merged_df = pd.concat([dict_df, comment_df])

# 2) 'en_word'와 'ko_word'로 groupby하고 'comment_cnt'의 합을 구함
grouped_df = merged_df.groupby(['en_word', 'ko_word'], as_index=False)['comment_cnt'].sum()

# 3) 결과 출력
print(grouped_df)

```

---

### 3.3. 협업 방식 및 문서화 체계 개선

#### 3.3.1. 기존 문제점
- 회의에서만 이슈가 공유되어 **동일 이슈 반복 발생**
- 이슈 히스토리 부재로 **중복 질의 증가**

#### 3.3.2. 개선 방향

##### 📌 Wiki 기반 협업 체계 구축
- 모든 이슈를 한 페이지에 사전 공유
- 표준 단어 규칙, Q&A, 변경 이력 등 구조적으로 자산화

##### 📌 슬랙 캔버스를 활용한 실시간 Q&A 체계
- 반복 질의는 위키로 이전하여 **검색 가능한 지식 기반화**

##### 📌 주차별 개인 일지 도입
- 작업 투명성 향상, 일정 관리 효율화

#### 3.3.3. 개선 결과
- 회의 시간 **약 30% 절감**, 핵심 논의에 집중 가능
- 정보 비대칭 감소 → **병렬 작업 효율 상승**
- 단어/용어 생성 규칙 일관성 확보 → **재사용성 증가**

---

## 4. 성과
- **데이터 표준화 성과**
  - 단어·용어·코드 일관성 확보  
  - 자연어 쿼리 기반 검색 품질 향상
- **협업 효율성 개선**
  - 위키·슬랙 도입으로 회의 생산성 증대, 지식 자산화
- **개인 기여**
  - 표준 단어 자동화 로직 개발  
  - 협업 프로세스 개선  
  - 장기적 관점의 지식 관리 체계 구축
