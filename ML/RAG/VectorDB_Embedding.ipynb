{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b509dd",
   "metadata": {},
   "source": [
    "## 사용자가 원하는 정보"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a092822",
   "metadata": {},
   "source": [
    "1. 사용자의 질문과 관련있는 데이터\n",
    "\n",
    "    - 관련이 있다는 것을 판단하는 기준은 vector가 된다.\n",
    "    - vector : 단어 또는 문장의 유사도를 파악해서 관련성을 측정한다.\n",
    "\n",
    "2. Vector를 생성하는 방법\n",
    "\n",
    "    - Embedding 모델을 활용해서 vector 생성한다.\n",
    "    - 문장에서 비슷한 단어가 자주 붙어있는 것을 학습한다.\n",
    "        - 예를 들어, A : \"왕은 왕자의 아버지다.\"  /  B : \"여왕은 왕자의 어머니다.\"\n",
    "        - \"왕자의\" 라는 단어 앞에 등장하는 \"왕\"과 \"여왕\"은 유사할 가능성이 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e6c40a",
   "metadata": {},
   "source": [
    "## Vector Databse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e1695",
   "metadata": {},
   "source": [
    "1. Embedding 모델을 활용해 생성된 vector를 저장한다.\n",
    "\n",
    "    - vector와 함꼐 metadata도 저장된다.\n",
    "        - metadata : 문서의 이름, 페이지 번호 등의 데이터\n",
    "    - hallucination을 대비하기 위해서 어떤 문서에서 가져왔는지 출처를 같이 보여주는 것이 중요하다.\n",
    "\n",
    "2. vector를 대상으로 유사도 검색을 한다.\n",
    "\n",
    "    - 사용자의 질문과 가장 비슷한 문서를 가져온다. (Retrieval)\n",
    "        - 소득세법을 RAG의 knowledge base로 활용한다.\n",
    "        - 문서 전체를 활용하게 되면 속도도 느리고, 토큰수 초과로 답변 생성이 안될 수 있다.\n",
    "        - 문서를 chunking하는 작업이 매우 중요하다.\n",
    "    \n",
    "    - 가져온 문서를 prompt를 통해서 LLM에 제공한다. (Augmented)\n",
    "    - LLM은 prompt를 활용해서 답변을 생성한다. (Generation)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ea907",
   "metadata": {},
   "source": [
    "### 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d56d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 패키지 설치\n",
    "#%pip install -q python-dotenv langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 환경변수 불러오기\n",
    "#  .env 파일에 OPENAI_API_KEY 등록\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21597d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. oepnai client 불러오기\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47fac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. numpy를 사용해서 코사인 유사도 계산\n",
    "\n",
    "import numpy as np\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two vectors.\n",
    "\n",
    "    parameters:\n",
    "    vec1 (numpy array) : First vector\n",
    "    vec2 (numpy array) : Second vector\n",
    "\n",
    "    Returns:\n",
    "    float : Cosine similarity between vec1 and vec2\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dot_product / (norm_vec1 * norm_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6a8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. \"King\" Embedding\n",
    "\n",
    "king_embedding_response = client.embeddings.create(\n",
    "    input=\"king\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "king_vector = np.array(king_embedding_response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2710d7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01040417,  0.02499519, -0.0014776 , ...,  0.00835009,\n",
       "        0.01049861, -0.00254005])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "king_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ffa62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. \"Queen\" Embedding\n",
    "\n",
    "queen_embedding_response = client.embeddings.create(\n",
    "    input=\"queen\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "queen_vector = np.array(queen_embedding_response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc121a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01385735,  0.0008602 , -0.0167823 , ...,  0.00017693,\n",
       "        0.01159847,  0.00638929])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "queen_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64177cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5552268369726672\n"
     ]
    }
   ],
   "source": [
    "# 7. King vector와 Queen vector의 코사인 유사도 계산\n",
    "\n",
    "similarity = cosine_similarity(king_vector, queen_vector)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20777b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2947745074537994\n"
     ]
    }
   ],
   "source": [
    "# 8. king과 slave의 유사도 계산\n",
    "\n",
    "slave_embedding_response = client.embeddings.create(\n",
    "    input=\"slave\",\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "slave_vector = np.array(slave_embedding_response.data[0].embedding)\n",
    "similarity_king_slave = cosine_similarity(king_vector, slave_vector)\n",
    "print(similarity_king_slave)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211e2cf",
   "metadata": {},
   "source": [
    "upstage api는 한국어에 성능이 더 좋다. 사용해보기!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
